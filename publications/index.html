<!DOCTYPE html>
<html>

  <head>
    <meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta http-equiv="X-UA-Compatible" content="IE=edge">

<title>Pablo  León-Villagrá | publications</title>
<meta name="description" content="">
<meta name="google-site-verification" content="gayTJ5B1vpxvJUWmBB7ds5Whevxxt4bMY2leFS6xkb4" />

<!-- Open Graph -->


<!-- Bootstrap & MDB -->
<link href="https://stackpath.bootstrapcdn.com/bootstrap/4.5.2/css/bootstrap.min.css" rel="stylesheet" integrity="sha512-MoRNloxbStBcD8z3M/2BmnT+rg4IsMxPkXaGh2zD6LGNNFE80W3onsAhRcMAMrSoyWL9xD7Ert0men7vR8LUZg==" crossorigin="anonymous">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/mdbootstrap/4.19.1/css/mdb.min.css" integrity="sha512-RO38pBRxYH3SoOprtPTD86JFOclM51/XTIdEPh5j8sj4tp8jmQIx26twG52UaLi//hQldfrh7e51WzP9wuP32Q==" crossorigin="anonymous" />

<!-- Fonts & Icons -->
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.14.0/css/all.min.css"  integrity="sha512-1PKOgIY59xJ8Co8+NE6FZ+LOAZKjy+KY8iq0G4B3CyeY6wYHN3yt9PW0XpSriVlkMXe40PTKnXrLnZ9+fkDaog==" crossorigin="anonymous">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/academicons/1.9.0/css/academicons.min.css" integrity="sha512-W4yqoT1+8NLkinBLBZko+dFB2ZbHsYLDdr50VElllRcNt2Q4/GSs6u71UHKxB7S6JEMCp5Ve4xjh3eGQl/HRvg==" crossorigin="anonymous">
<link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons">

<!-- Code Syntax Highlighting -->
<link rel="stylesheet" href="https://gitcdn.link/repo/jwarby/jekyll-pygments-themes/master/github.css" />

<!-- Styles -->
<link rel="shortcut icon" href="/assets/img/logo.jpg">
<link rel="stylesheet" href="/assets/css/main.css">

<link rel="canonical" href="/publications/">

<!-- Theming-->


    
<!-- MathJax -->
<script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.1.2/es5/tex-mml-chtml.js"></script>
<script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>


  </head>

  <body class="fixed-top-nav ">

    <!-- Header -->

    <header>

    <!-- Nav Bar -->
    <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top">
    <div class="container">
      
      <a class="navbar-brand title font-weight-lighter" href="/">
       <span class="font-weight-bold">Pablo</span>   León-Villagrá
      </a>
      
      <!-- Navbar Toogle -->
      <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation">
        <span class="sr-only">Toggle navigation</span>
        <span class="icon-bar top-bar"></span>
        <span class="icon-bar middle-bar"></span>
        <span class="icon-bar bottom-bar"></span>
      </button>
      <div class="collapse navbar-collapse text-right" id="navbarNav">
        <ul class="navbar-nav ml-auto flex-nowrap">
          <!-- About -->
          <li class="nav-item ">
            <a class="nav-link" href="/">
              about
              
            </a>
          </li>
          
          <!-- Other pages -->
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          <li class="nav-item active">
              <a class="nav-link" href="/publications/">
                publications
                
                <span class="sr-only">(current)</span>
                
              </a>
          </li>
          
          
          <li class="nav-item">
            <a class="nav-link" href="/assets/pdf/CV.pdf" target="_blank">CV</a></li>
          
        </ul>
      </div>
    </div>
  </nav>

</header>


    <!-- Content -->

    <div class="container mt-5">
      <div class="post">

  <header class="post-header">
    <h1 class="post-title">publications</h1>
    <p class="post-description"></p>
  </header>

  <article>
    <div class="publications">


  <h2 class="year">2020</h2>
  <ol class="bibliography"><li><div class="row">
  <div class="col-sm-2 abbr">
  
    
    <abbr class="badge">CogSci</abbr>
    
  
  </div>

  <div id="leonotsubo" class="col-sm-8">
    
      <div class="title">Uncovering Category Representations with Linked MCMC with people</div>
      <div class="author">
        
          
            
              
                <em>León-Villagrá, Pablo</em>,
              
            
          
        
          
            
              
                
                  Otsubo, Kay,
                
              
            
          
        
          
            
              
                
                  <a href="http://www.christopherglucas.com" target="_blank">Lucas, Christopher G</a>,
                
              
            
          
        
          
            
              
                
                  and <a href="https://www.brown.edu/academics/cognitive-linguistic-psychological-sciences/people/faculty/daphna-buchsbaum" target="_blank">Buchsbaum, Daphna</a>
                
              
            
          
        
      </div>

      <div class="periodical">
      
        <em>Proceedings of the 42nd Annual Conference of the Cognitive Science Society</em>
      
      
        2020
      
      </div>
    

    <div class="links">
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
    
    
    
      <a href="https://cognitivesciencesociety.org/cogsci20/papers/0378/" class="btn btn-sm z-depth-0" role="button" target="_blank">HTML</a>
    
    
      
      <a href="/assets/pdf/0378.pdf" class="btn btn-sm z-depth-0" role="button" target="_blank">PDF</a>
      
    
    
    
    
    
    
    
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>Cognitive science is often concerned with questions about our representations of concepts and the underlying psychological spaces in which these concepts are embedded. One method to reveal concepts and conceptual spaces experimentally is Markov chain Monte Carlo with people (MCMCP), where participants produce samples from their implicit categories. While MCMCP has allowed for the experimental study of psychological representations of complex categories, experiments are typically long and repetitive. Here, we contrasted the classical MCMCP design with a linked variant, in which each participant completed just a short run of MCMCP trials, which were then combined to produce a single sample set. We found that linking produced results that were nearly indistinguishable from classical MCMCP, and often converged to the desired distribution faster. Our results support linking as an approach for performing MCMCP experiments within broader populations, such as in developmental settings where large numbers of trials per participant are impractical.</p>
    </div>
    
  </div>
</div>
</li>
<li><div class="row">
  <div class="col-sm-2 abbr">
  
  </div>

  <div id="chater2020probabilistic" class="col-sm-8">
    
      <div class="title">Probabilistic biases meet the Bayesian brain</div>
      <div class="author">
        
          
            
              
                
                  <a href="https://www.wbs.ac.uk/about/person/nick-chater/" target="_blank">Chater, Nick</a>,
                
              
            
          
        
          
            
              
                
                  Zhu, Jian-Qiao,
                
              
            
          
        
          
            
              
                
                  Spicer, Jake,
                
              
            
          
        
          
            
              
                
                  Sundh, Joakim,
                
              
            
          
        
          
            
              
                <em>León-Villagrá, Pablo</em>,
              
            
          
        
          
            
              
                
                  and <a href="https://warwick.ac.uk/fac/sci/psych/people/asanborn/" target="_blank">Sanborn, Adam</a>
                
              
            
          
        
      </div>

      <div class="periodical">
      
        <em>Current Directions in Psychological Science</em>
      
      
        2020
      
      </div>
    

    <div class="links">
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
    
    
    
      <a href="https://journals.sagepub.com/doi/full/10.1177/0963721420954801" class="btn btn-sm z-depth-0" role="button" target="_blank">HTML</a>
    
    
      
      <a href="/assets/pdf/0963721420954801.pdf" class="btn btn-sm z-depth-0" role="button" target="_blank">PDF</a>
      
    
    
    
    
    
    
    
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>In Bayesian cognitive science, the mind is seen as a spectacular probabilistic-inference machine. But judgment and
decision-making (JDM) researchers have spent half a century uncovering how dramatically and systematically people
depart from rational norms. In this article, we outline recent research that opens up the possibility of an unexpected
reconciliation. The key hypothesis is that the brain neither represents nor calculates with probabilities but approximates
probabilistic calculations by drawing samples from memory or mental simulation. Sampling models diverge from
perfect probabilistic calculations in ways that capture many classic JDM findings, which offers the hope of an integrated
explanation of classic heuristics and biases, including availability, representativeness, and anchoring and adjustment.</p>
    </div>
    
  </div>
</div>
</li></ol>

  <h2 class="year">2019</h2>
  <ol class="bibliography"><li><div class="row">
  <div class="col-sm-2 abbr">
  
    
    <abbr class="badge">CogSci</abbr>
    
  
  </div>

  <div id="leonsanborn" class="col-sm-8">
    
      <div class="title">Generalizing Functions in Sparse Domains</div>
      <div class="author">
        
          
            
              
                <em>León-Villagrá, Pablo</em>,
              
            
          
        
          
            
              
                
                  and <a href="http://www.christopherglucas.com" target="_blank">Lucas, Christopher G</a>
                
              
            
          
        
      </div>

      <div class="periodical">
      
        <em>Proceedings of the 41st Annual Conference of the Cognitive Science Society</em>
      
      
        2019
      
      </div>
    

    <div class="links">
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
    
    
    
      <a href="https://cogsci.mindmodeling.org/2019/papers/0369/" class="btn btn-sm z-depth-0" role="button" target="_blank">HTML</a>
    
    
      
      <a href="/assets/pdf/0369.pdf" class="btn btn-sm z-depth-0" role="button" target="_blank">PDF</a>
      
    
    
    
    
    
    
    
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>We propose that when humans learn sets of relationships they are able to learn the abstract structure or type of a family of relationships, and exploit that knowledge to improve their ability to learn and generalize in the future, especially in the face of sparse or ambiguous data. In two experiments we found that participants choose patterns and extrapolate in ways consistent with sets of previously learned relations, as measured by extrapolation judgments and forced-choice tasks. We take these results to suggest that humans can detect shared abstract relations and apply this learned regularity to perform rapid and flexible generalization.</p>
    </div>
    
  </div>
</div>
</li>
<li><div class="row">
  <div class="col-sm-2 abbr">
  
    
    <abbr class="badge">CogSci</abbr>
    
  
  </div>

  <div id="leonlucas2" class="col-sm-8">
    
      <div class="title">Exploring the Representation of Linear Functions</div>
      <div class="author">
        
          
            
              
                <em>León-Villagrá, Pablo</em>,
              
            
          
        
          
            
              
                
                  <a href="" target="_blank">Klar, Verena S.</a>,
                
              
            
          
        
          
            
              
                
                  <a href="https://warwick.ac.uk/fac/sci/psych/people/asanborn/" target="_blank">Sanborn, Adam N.</a>,
                
              
            
          
        
          
            
              
                
                  and <a href="http://www.christopherglucas.com" target="_blank">Lucas, Christopher G</a>
                
              
            
          
        
      </div>

      <div class="periodical">
      
        <em>Proceedings of the 41st Annual Conference of the Cognitive Science Society</em>
      
      
        2019
      
      </div>
    

    <div class="links">
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
    
    
    
      <a href="https://cogsci.mindmodeling.org/2019/papers/0368/" class="btn btn-sm z-depth-0" role="button" target="_blank">HTML</a>
    
    
      
      <a href="/assets/pdf/0368.pdf" class="btn btn-sm z-depth-0" role="button" target="_blank">PDF</a>
      
    
    
    
    
    
    
    
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>Function learning research has highlighted the importance of human inductive biases that facilitate long-range extrapolations. However, most previous research is focused on aggregate errors or single-criterion extrapolations. Thus, little is known about the underlying psychological space in which continuous relationships are represented. We ask whether people can learn the distributional properties of new classes of relationships, using Markov Chain Monte Carlo with People, and find that (1) people are able to track not just the expected parameters of a linear function, but information about the variability of functions in a specific context and (2) in many cases these spaces over parameters exhibit multiple modes.</p>
    </div>
    
  </div>
</div>
</li></ol>

  <h2 class="year">2018</h2>
  <ol class="bibliography"><li><div class="row">
  <div class="col-sm-2 abbr">
  
    
    <abbr class="badge">CogSci</abbr>
    
  
  </div>

  <div id="leonpreda" class="col-sm-8">
    
      <div class="title">Data Availability and Function Extrapolation</div>
      <div class="author">
        
          
            
              
                <em>León-Villagrá, Pablo</em>,
              
            
          
        
          
            
              
                
                  Preda, Irina,
                
              
            
          
        
          
            
              
                
                  and <a href="http://www.christopherglucas.com" target="_blank">Lucas, Christopher G</a>
                
              
            
          
        
      </div>

      <div class="periodical">
      
        <em>Proceedings of the 40th Annual Conference of the Cognitive Science Society</em>
      
      
        2018
      
      </div>
    

    <div class="links">
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
    
    
    
      <a href="https://cogsci.mindmodeling.org/2018/papers/0385/" class="btn btn-sm z-depth-0" role="button" target="_blank">HTML</a>
    
    
      
      <a href="/assets/pdf/0385.pdf" class="btn btn-sm z-depth-0" role="button" target="_blank">PDF</a>
      
    
    
    
    
    
    
    
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>In function learning experiments, where participants learn relationships from sequentially-presented examples, people show a strong tacit expectation that most relationships are linear, and struggle to learn and extrapolate from non-linear relationships. In contrast, experiments with similar tasks where data are presented simultaneously – typically using scatter plots – have shown that human learners can discover and extrapolate from complex non-linear trends. Do people have different expectations in these task types, or can the results be attributed to effects of memory and data availability? In a direct comparison of both paradigms, we found that differences between task types can be attributed to data availability. We show that a simple memory-limited Bayesian model is consistent with human extrapolations for linear data for both high and low data availability. However, our model underestimates the participants’ ability to infer non-monotonic functions, especially when data is sparse. This suggest that people track higher-order properties of functions when learning and generalizing.</p>
    </div>
    
  </div>
</div>
</li>
<li><div class="row">
  <div class="col-sm-2 abbr">
  
  </div>

  <div id="leon2018" class="col-sm-8">
    
      <div class="title">You Guessed it! Reflecting on Preconceptions and Exploring Data without Statistics</div>
      <div class="author">
        
          
            
              
                <em>León-Villagrá, Pablo</em>,
              
            
          
        
          
            
              
                
                  <a href="https://www.researchgate.net/profile/Sarwar_Mozumder" target="_blank">Islam, Sarwar</a>,
                
              
            
          
        
          
            
              
                
                  Lucero, Megan,
                
              
            
          
        
          
            
              
                
                  <a href="https://tbrx.github.io/" target="_blank">Paige, Brooks</a>,
                
              
            
          
        
          
            
              
                
                  and <a href="http://tomasp.net/" target="_blank">Petricek, Tomas</a>
                
              
            
          
        
      </div>

      <div class="periodical">
      
        <em>In Proceedings of the 2nd European Data and Computational Journalism Conference</em>
      
      
        2018
      
      </div>
    

    <div class="links">
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
    
    
    
      <a href="https://researchrepository.ucd.ie/handle/10197/9416" class="btn btn-sm z-depth-0" role="button" target="_blank">HTML</a>
    
    
      
      <a href="/assets/pdf/youguess.pdf" class="btn btn-sm z-depth-0" role="button" target="_blank">PDF</a>
      
    
    
    
    
    
    
    
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>We live in times in which information is abundant, but trust in expert analysis is low. How can we make complex 
issues accessible for readers and overcome their preconceptions? We propose a novel way of presenting readers with data and 
raising awareness for individual bias and preconceptions. In our application, readers freely choose potentially relevant factors 
in societally relevant issues and reflect on their choices in an engaging, non-threatening way. We suggest that such an 
approach allows for more engaged and open-minded readers and as a result can facilitate democratic, data-centric debate.</p>
    </div>
    
  </div>
</div>
</li></ol>

  <h2 class="year">2017</h2>
  <ol class="bibliography"><li><div class="row">
  <div class="col-sm-2 abbr">
  
  </div>

  <div id="matthews2017gpflow" class="col-sm-8">
    
      <div class="title">GPflow: A Gaussian Process Library using TensorFlow</div>
      <div class="author">
        
          
            
              
                
                  <a href="http://mlg.eng.cam.ac.uk/?portfolio=alex-matthews" target="_blank">Matthews, Alexander</a>,
                
              
            
          
        
          
            
              
                
                  Van Der Wilk, Mark,
                
              
            
          
        
          
            
              
                
                  Nickson, Tom,
                
              
            
          
        
          
            
              
                
                  Fujii, Keisuke,
                
              
            
          
        
          
            
              
                
                  Boukouvalas, Alexis,
                
              
            
          
        
          
            
              
                <em>León-Villagrá, Pablo</em>,
              
            
          
        
          
            
              
                
                  <a href="http://mlg.eng.cam.ac.uk/zoubin/" target="_blank">Ghahramani, Zoubin</a>,
                
              
            
          
        
          
            
              
                
                  and Hensman, James
                
              
            
          
        
      </div>

      <div class="periodical">
      
        <em>The Journal of Machine Learning Research</em>
      
      
        2017
      
      </div>
    

    <div class="links">
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
    
    
    
      <a href="https://dl.acm.org/doi/abs/10.5555/3122009.3122049" class="btn btn-sm z-depth-0" role="button" target="_blank">HTML</a>
    
    
      
      <a href="/assets/pdf/gpflow.pdf" class="btn btn-sm z-depth-0" role="button" target="_blank">PDF</a>
      
    
    
    
    
    
    
    
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>GPflow is a Gaussian process library that uses TensorFlow for its core computations and Python for its front end. The distinguishing features of GPflow are that it uses variational inference as the primary approximation method, provides concise code through the use of automatic differentiation, has been engineered with a particular emphasis on software testing and is able to exploit GPU hardware.</p>
    </div>
    
  </div>
</div>
</li></ol>

  <h2 class="year">2013</h2>
  <ol class="bibliography"><li><div class="row">
  <div class="col-sm-2 abbr">
  
    
    <abbr class="badge">CogSci</abbr>
    
  
  </div>

  <div id="leonjaekel" class="col-sm-8">
    
      <div class="title">Categorization and Abstract Similarity in Chess</div>
      <div class="author">
        
          
            
              
                <em>León-Villagrá, Pablo</em>,
              
            
          
        
          
            
              
                
                  and <a href="https://www.psychologie.tu-darmstadt.de/models-of-higher-cognition/mod/mem/frank/index.en.jsp" target="_blank">Jäkel, Frank</a>
                
              
            
          
        
      </div>

      <div class="periodical">
      
        <em>Proceedings of the 35th Annual Conference of the Cognitive Science Society</em>
      
      
        2013
      
      </div>
    

    <div class="links">
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
    
    
    
      <a href="https://cogsci.mindmodeling.org/2013/papers/0513/" class="btn btn-sm z-depth-0" role="button" target="_blank">HTML</a>
    
    
      
      <a href="/assets/pdf/0513.pdf" class="btn btn-sm z-depth-0" role="button" target="_blank">PDF</a>
      
    
    
    
    
    
    
    
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>Chess experts remember meaningful chess positions better than novices (de Groot, 1978; Chase &amp; Simon, 1973). This can be explained with a larger number of chunks in experts’ long-term memory (Gobet &amp; Simon, 1998). These chunks are mainly based on visual representations, that is, pieces on squares. However, a recent experiment highlighted that experts prefer to group chess positions by abstract similarities that cannot be explained purely visually (Linhares &amp; Brum, 2007). Based on these data it was claimed that chess expertise, in addition to chunks, crucially relies on abstraction and analogies. These data and the conclusions were heavily criticized because the instructions strongly biased the participants to group positions in a certain way (Bilali’c &amp; Gobet, 2009). Here, we successfully replicated this experiment with less explicit instructions. In addition, we collected category labels for the groupings that allowed us to explore the abstract principles that participants used.</p>
    </div>
    
  </div>
</div>
</li></ol>


</div>

  </article>

</div>

    </div>

    <!-- Footer -->

    
<footer class="fixed-bottom">
  <div class="container mt-0">
    <!-- &copy; Copyright 2021 Pablo  León-Villagrá.-->
    
    
    Last updated: February 10, 2021.
    
  </div>
</footer>



  </body>

  <!-- jQuery -->
<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js" integrity="sha512-bLT0Qm9VnAYZDflyKcBaQ2gg0hSYNQrJ8RilYldYQ1FxQYoCLtUjuuRuZo+fjqhx/qtq/1itJ0C2ejDxltZVFg==" crossorigin="anonymous"></script>

  <!-- Bootsrap & MDB scripts -->
<script src="https://cdnjs.cloudflare.com/ajax/libs/popper.js/2.4.4/umd/popper.min.js" integrity="sha512-eUQ9hGdLjBjY3F41CScH3UX+4JDSI9zXeroz7hJ+RteoCaY+GP/LDoM8AO+Pt+DRFw3nXqsjh9Zsts8hnYv8/A==" crossorigin="anonymous"></script>
<script src="https://stackpath.bootstrapcdn.com/bootstrap/4.5.2/js/bootstrap.min.js" integrity="sha512-M5KW3ztuIICmVIhjSqXe01oV2bpe248gOxqmlcYrEzAvws7Pw3z6BK0iGbrwvdrUQUhi3eXgtxp5I8PDo9YfjQ==" crossorigin="anonymous"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/mdbootstrap/4.19.1/js/mdb.min.js" integrity="sha512-Mug9KHKmroQFMLm93zGrjhibM2z2Obg9l6qFG2qKjXEXkMp/VDkI4uju9m4QKPjWSwQ6O2qzZEnJDEeCw0Blcw==" crossorigin="anonymous"></script>

  
<!-- Mansory & imagesLoaded -->
<script defer src="https://unpkg.com/masonry-layout@4/dist/masonry.pkgd.min.js"></script>
<script defer src="https://unpkg.com/imagesloaded@4/imagesloaded.pkgd.min.js"></script>
<script defer src="/assets/js/mansory.js" type="text/javascript"></script>


  


<!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-181562575-1"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag() { dataLayer.push(arguments); }
  gtag('js', new Date());

  gtag('config', 'UA-181562575-1');
</script>


<!-- Load Common JS -->
<script src="/assets/js/common.js"></script>

<!-- Load DarkMode JS -->
<script src="/assets/js/dark_mode.js"></script>


</html>
