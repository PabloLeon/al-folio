---
---

@string{aps = {American Physical Society,}}

@book{einstein1956investigations,
  title={Investigations on the Theory of the Brownian Movement},
  author={Einstein, Albert},
  year={1956},
  publisher={Courier Corporation,}
}

@article{einstein1950meaning,
  abbr={AJP},
  title={The meaning of relativity},
  author={Einstein, Albert and Taub, AH},
  journal={American Journal of Physics,},
  volume={18},
  number={6},
  pages={403--404},
  year={1950},
  publisher={American Association of Physics Teachers,}
}

@article{PhysRev.47.777,
  abbr={PhysRev},
  title={Can Quantum-Mechanical Description of Physical Reality Be Considered Complete?},
  author={Einstein, A. and Podolsky, B. and Rosen, N.},
  abstract={In a complete theory there is an element corresponding to each element of reality. A sufficient condition for the reality of a physical quantity is the possibility of predicting it with certainty, without disturbing the system. In quantum mechanics in the case of two physical quantities described by non-commuting operators, the knowledge of one precludes the knowledge of the other. Then either (1) the description of reality given by the wave function in quantum mechanics is not complete or (2) these two quantities cannot have simultaneous reality. Consideration of the problem of making predictions concerning a system on the basis of measurements made on another system that had previously interacted with it leads to the result that if (1) is false then (2) is also false. One is thus led to conclude that the description of reality as given by a wave function is not complete.},
  journal={Phys. Rev.,},
  volume={47},
  issue={10},
  pages={777--780},
  numpages={0},
  year={1935},
  month={May},
  publisher=aps,
  doi={10.1103/PhysRev.47.777},
  url={http://link.aps.org/doi/10.1103/PhysRev.47.777},
  html={https://journals.aps.org/pr/abstract/10.1103/PhysRev.47.777},
  pdf={example_pdf.pdf},
}

@article{einstein1905molekularkinetischen,
  title={{\"U}ber die von der molekularkinetischen Theorie der W{\"a}rme geforderte Bewegung von in ruhenden Fl{\"u}ssigkeiten suspendierten Teilchen},
  author={Einstein, A.},
  journal={Annalen der physik,},
  volume={322},
  number={8},
  pages={549--560},
  year={1905},
  publisher={Wiley Online Library}
}

@article{einstein1905movement,
  abbr={Ann. Phys.},
  title={Un the movement of small particles suspended in statiunary liquids required by the molecular-kinetic theory 0f heat},
  author={Einstein, A.},
  journal={Ann. Phys.,},
  volume={17},
  pages={549--560},
  year={1905}
}



@article{leonjaekel,
author = {Le{\'o}n-Villagr{\'a}, Pablo and J{\"a}kel, Frank},
journal = {Proceedings of the 35th Annual Conference of the Cognitive Science Society},
title = {Categorization and Abstract Similarity in Chess},
abbr = {CogSci},
year = {2013},
html = {https://cogsci.mindmodeling.org/2013/papers/0513/},
pdf = {0513.pdf},
abstract = {Chess experts remember meaningful chess positions better than novices (de Groot, 1978; Chase & Simon, 1973). This can be explained with a larger number of chunks in experts' long-term memory (Gobet & Simon, 1998). These chunks are mainly based on visual representations, that is, pieces on squares. However, a recent experiment highlighted that experts prefer to group chess positions by abstract similarities that cannot be explained purely visually (Linhares & Brum, 2007). Based on these data it was claimed that chess expertise, in addition to chunks, crucially relies on abstraction and analogies. These data and the conclusions were heavily criticized because the instructions strongly biased the participants to group positions in a certain way (Bilali'c & Gobet, 2009). Here, we successfully replicated this experiment with less explicit instructions. In addition, we collected category labels for the groupings that allowed us to explore the abstract principles that participants used.}
}
@article{matthews2017gpflow,
  title={GPflow: A Gaussian Process Library using TensorFlow},
  author={Matthews, Alexander and Van Der Wilk, Mark and Nickson, Tom and Fujii, Keisuke and Boukouvalas, Alexis and Le{\'o}n-Villagr{\'a}, Pablo and Ghahramani, Zoubin and Hensman, James},
  journal={The Journal of Machine Learning Research},
  volume={18},
  number={1},
  pages={1299--1304},
  year={2017},
  publisher={JMLR.org},
  pdf = {gpflow.pdf},
  abstract = {GPflow is a Gaussian process library that uses TensorFlow for its core computations and Python for its front end. The distinguishing features of GPflow are that it uses variational inference as the primary approximation method, provides concise code through the use of automatic differentiation, has been engineered with a particular emphasis on software testing and is able to exploit GPU hardware.},
  html = {https://dl.acm.org/doi/abs/10.5555/3122009.3122049}
}


@article{leonpreda,
author = {Le{\'o}n-Villagr{\'a}, Pablo and Preda, Irina and Lucas, Christopher G},
journal = {Proceedings of the 40th Annual Conference of the Cognitive Science Society},
title = {Data Availability and Function Extrapolation},
abbr = {CogSci},
html = {https://cogsci.mindmodeling.org/2018/papers/0385/},
abstract = {In function learning experiments, where participants learn relationships from sequentially-presented examples, people show a strong tacit expectation that most relationships are linear, and struggle to learn and extrapolate from non-linear relationships. In contrast, experiments with similar tasks where data are presented simultaneously – typically using scatter plots – have shown that human learners can discover and extrapolate from complex non-linear trends. Do people have different expectations in these task types, or can the results be attributed to effects of memory and data availability? In a direct comparison of both paradigms, we found that differences between task types can be attributed to data availability. We show that a simple memory-limited Bayesian model is consistent with human extrapolations for linear data for both high and low data availability. However, our model underestimates the participants’ ability to infer non-monotonic functions, especially when data is sparse. This suggest that people track higher-order properties of functions when learning and generalizing.},
pdf = {0385.pdf},
year = {2018},
}
@inproceedings{leon2018,
  title={You Guessed it! Reflecting on Preconceptions and Exploring Data without Statistics},
  author={Le{\'o}n-Villagr{\'a}, Pablo and Islam, Sarwar and Lucero, Megan and Paige, Brooks and Petricek, Tomas},
  booktitle={Proceedings of the 2nd European Data and Computational Journalism Conference},
  html = {https://researchrepository.ucd.ie/handle/10197/9416},
  pages={11},
  abstract = {We live in times in which information is abundant, but trust in expert analysis is low. How can we make complex 
issues accessible for readers and overcome their preconceptions? We propose a novel way of presenting readers with data and 
raising awareness for individual bias and preconceptions. In our application, readers freely choose potentially relevant factors 
in societally relevant issues and reflect on their choices in an engaging, non-threatening way. We suggest that such an 
approach allows for more engaged and open-minded readers and as a result can facilitate democratic, data-centric debate.},
  pdf = {youguess.pdf},
  year={2018},
  organization={University College Dublin}
}
@article{leonsanborn,
author = {Le{\'o}n-Villagr{\'a}, Pablo and  Lucas, Christopher G},
journal = {Proceedings of the 41st Annual Conference of the Cognitive Science Society},
abbr = {CogSci},
title = {Generalizing Functions in Sparse Domains},
year = {2019},
html = {https://cogsci.mindmodeling.org/2019/papers/0369/},
pdf = {0369.pdf},
abstract = {We propose that when humans learn sets of relationships they are able to learn the abstract structure or type of a family of relationships, and exploit that knowledge to improve their ability to learn and generalize in the future, especially in the face of sparse or ambiguous data. In two experiments we found that participants choose patterns and extrapolate in ways consistent with sets of previously learned relations, as measured by extrapolation judgments and forced-choice tasks. We take these results to suggest that humans can detect shared abstract relations and apply this learned regularity to perform rapid and flexible generalization.},
}
@article{leonlucas2,
author = {Le{\'o}n-Villagr{\'a}, Pablo and Klar, Verena S. and Sanborn, Adam N. and Lucas, Christopher G},
journal = {Proceedings of the 41st Annual Conference of the Cognitive Science Society},
title = {Exploring the Representation of Linear Functions},
html={https://cogsci.mindmodeling.org/2019/papers/0368/},
abbr = {CogSci},
year = {2019},
pdf = {0368.pdf},
abstract = {Function learning research has highlighted the importance of human inductive biases that facilitate long-range extrapolations. However, most previous research is focused on aggregate errors or single-criterion extrapolations. Thus, little is known about the underlying psychological space in which continuous relationships are represented. We ask whether people can learn the distributional properties of new classes of relationships, using Markov Chain Monte Carlo with People, and find that (1) people are able to track not just the expected parameters of a linear function, but information about the variability of functions in a specific context and (2) in many cases these spaces over parameters exhibit multiple modes.},
}
@article{leonotsubo,
author = {Le{\'o}n-Villagr{\'a}, Pablo and Otsubo, Kay and  Lucas, Christopher G and Buchsbaum, Daphna},
journal = {Proceedings of the 42nd Annual Conference of the Cognitive Science Society},
title = {Uncovering Category Representations with Linked MCMC with people},
year = {2020},
selected = {true},
abbr = {CogSci},
html={https://cognitivesciencesociety.org/cogsci20/papers/0378/},
pdf={0378.pdf},
abstract={Cognitive science is often concerned with questions about our representations of concepts and the underlying psychological spaces in which these concepts are embedded. One method to reveal concepts and conceptual spaces experimentally is Markov chain Monte Carlo with people (MCMCP), where participants produce samples from their implicit categories. While MCMCP has allowed for the experimental study of psychological representations of complex categories, experiments are typically long and repetitive. Here, we contrasted the classical MCMCP design with a linked variant, in which each participant completed just a short run of MCMCP trials, which were then combined to produce a single sample set. We found that linking produced results that were nearly indistinguishable from classical MCMCP, and often converged to the desired distribution faster. Our results support linking as an approach for performing MCMCP experiments within broader populations, such as in developmental settings where large numbers of trials per participant are impractical.},
}

@article{chater2020probabilistic,
  title={Probabilistic biases meet the Bayesian brain},
  author={Chater, Nick and Zhu, Jian-Qiao and Spicer, Jake and Sundh, Joakim and Le{\'o}n-Villagr{\'a}, Pablo and Sanborn, Adam},
  journal={Current Directions in Psychological Science},
  volume={29},
  number={5},
  pages={506--512},
  year={2020},
  publisher={SAGE Publications Sage CA: Los Angeles, CA},
  html={https://journals.sagepub.com/doi/full/10.1177/0963721420954801},
  pdf={0963721420954801.pdf},
  abstract={In Bayesian cognitive science, the mind is seen as a spectacular probabilistic-inference machine. But judgment and
decision-making (JDM) researchers have spent half a century uncovering how dramatically and systematically people
depart from rational norms. In this article, we outline recent research that opens up the possibility of an unexpected
reconciliation. The key hypothesis is that the brain neither represents nor calculates with probabilities but approximates
probabilistic calculations by drawing samples from memory or mental simulation. Sampling models diverge from
perfect probabilistic calculations in ways that capture many classic JDM findings, which offers the hope of an integrated
explanation of classic heuristics and biases, including availability, representativeness, and anchoring and adjustment.}
}